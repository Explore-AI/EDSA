{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling Text Data in Machine Learning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Natural Language Processing](http://img.youtube.com/vi/8S3qHHUKqYk/0.jpg)](http://www.youtube.com/watch?v=8S3qHHUKqYk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial introduces the following key concepts in handling unstructured text data in python for machine learning.  We will be covering the following concepts:\n",
    "\n",
    "## Individual words analysis\n",
    "* Removing Noise\n",
    "* Tokenising\n",
    "* Stemming \n",
    "* Lemmatisation\n",
    "* Stop Words\n",
    "* n-grams\n",
    "* Bag of words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence structure analysis\n",
    "The following concepts are also very useful for text analysis, so please feel free to do more research and see if you can implement these with the MBTI dataset\n",
    "* Part of Speech Tagging\n",
    "* Named Entity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we get started, lets get the data and the main library we will be using:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [NLTK](http://www.nltk.org/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLTK - natural language toolkit - is a leading library for building Python programs to work with human language data. It provides easy-to-use interfaces to over 50 corpora and lexical resources such as WordNet, along with a suite of text processing libraries for classification, tokenization, stemming, tagging, parsing, and semantic reasoning (more on this stuff below), wrappers for industrial-strength NLP libraries, and an active discussion forum.\n",
    "\n",
    "Thanks to a hands-on guide introducing programming fundamentals alongside topics in computational linguistics, plus comprehensive API documentation, NLTK is suitable for linguists, engineers, students, educators, researchers, and industry users alike. NLTK is available for Windows, Mac OS X, and Linux. Best of all, NLTK is a free, open source, community-driven project.\n",
    "\n",
    "Natural Language Processing with Python provides a practical introduction to programming for language processing. Written by the creators of NLTK, it guides the reader through the fundamentals of writing Python programs, working with corpora, categorizing text, analyzing linguistic structure, and more. The book is being updated for Python 3 and NLTK 3. (The original Python 2 version is still available at http://nltk.org/.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's get the data and clean it up a bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mbti = pd.read_csv('../7_Data/mbti_1.csv')\n",
    "mbti = mbti\n",
    "\n",
    "# List of mbti types \n",
    "type_labels = ['ISTJ', 'ISFJ', 'INFJ', 'INTJ', \n",
    "               'ISTP', 'ISFP', 'INFP', 'INTP', \n",
    "               'ESTP', 'ESFP', 'ENFP', 'ENTP', \n",
    "               'ESTJ', 'ESFJ', 'ENFJ', 'ENTJ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>'http://www.youtube.com/watch?v=qsXHcwe3krw|||...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>'I'm finding the lack of me in these posts ver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INTP</td>\n",
       "      <td>'Good one  _____   https://www.youtube.com/wat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>'Dear INTP,   I enjoyed our conversation the o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>'You're fired.|||That's another silly misconce...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                              posts\n",
       "0  INFJ  'http://www.youtube.com/watch?v=qsXHcwe3krw|||...\n",
       "1  ENTP  'I'm finding the lack of me in these posts ver...\n",
       "2  INTP  'Good one  _____   https://www.youtube.com/wat...\n",
       "3  INTJ  'Dear INTP,   I enjoyed our conversation the o...\n",
       "4  ENTJ  'You're fired.|||That's another silly misconce..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mbti.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8675 entries, 0 to 8674\n",
      "Data columns (total 2 columns):\n",
      "type     8675 non-null object\n",
      "posts    8675 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 135.6+ KB\n"
     ]
    }
   ],
   "source": [
    "mbti.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets have a look at how many of the different MBTI types we have data for. It looks like we have very few sample for the 'ES' types.  Maybe because they are out in the real-world, not sitting behind a computer screen! :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeoAAAFbCAYAAAAa+83qAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1140b3d30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mbti['type'].value_counts().plot(kind = 'bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets increase the size of the dataset by converting each of the 50 posts into the `posts` column into its own row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_mbti = []\n",
    "for i, row in mbti.iterrows():\n",
    "    for post in row['posts'].split('|||'):\n",
    "        all_mbti.append([row['type'], post])\n",
    "all_mbti = pd.DataFrame(all_mbti, columns=['type', 'post'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(422845, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many rows do we have now?\n",
    "all_mbti.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>post</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>'http://www.youtube.com/watch?v=qsXHcwe3krw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>http://41.media.tumblr.com/tumblr_lfouy03PMA1q...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>enfp and intj moments  https://www.youtube.com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>What has been the most life-changing experienc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>http://www.youtube.com/watch?v=vXZeYwwRDw8   h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                               post\n",
       "0  INFJ        'http://www.youtube.com/watch?v=qsXHcwe3krw\n",
       "1  INFJ  http://41.media.tumblr.com/tumblr_lfouy03PMA1q...\n",
       "2  INFJ  enfp and intj moments  https://www.youtube.com...\n",
       "3  INFJ  What has been the most life-changing experienc...\n",
       "4  INFJ  http://www.youtube.com/watch?v=vXZeYwwRDw8   h..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_mbti.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe8AAAFbCAYAAAD80gauAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11ea42860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_mbti['type'].value_counts().plot(kind = 'bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing Noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In text analytics, removing unneccesary information is a key part of getting the data into a usable format.  Some techniques are standard, while your own data will require some creative thinking on your part.\n",
    "\n",
    "For the MBTI data set we will be doing the following steps:\n",
    "* removing the web-urls\n",
    "* making everything lower case\n",
    "* removing punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [Regular expressions](https://www.regular-expressions.info/) can be very useful for extracting information from text.  If you feel brave, go teach yourself all about it... If not, just follow along.  This next step effectively removes all websites and replaces them with the text `web-url` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pattern_url = r'http[s]?://(?:[A-Za-z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9A-Fa-f][0-9A-Fa-f]))+'\n",
    "subs_url = r'url-web'\n",
    "all_mbti['post'] = all_mbti['post'].replace(to_replace = pattern_url, value = subs_url, regex = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>post</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>'url-web</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>url-web</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>enfp and intj moments  url-web  sportscenter n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>What has been the most life-changing experienc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>url-web   url-web  On repeat for most of today.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                               post\n",
       "0  INFJ                                           'url-web\n",
       "1  INFJ                                            url-web\n",
       "2  INFJ  enfp and intj moments  url-web  sportscenter n...\n",
       "3  INFJ  What has been the most life-changing experienc...\n",
       "4  INFJ    url-web   url-web  On repeat for most of today."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_mbti.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Seed of an idea... There seem to be a lot of youtube and other links embedded.  Maybe you can think of ways to collect even more information from these links?  How about page titles and names of Youtube videos?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# first we make everything lower case to remove some noise from capitalisation\n",
    "all_mbti['post'] = all_mbti['post'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "# these are the chars that count as punctuation. Let's remove the punctuation\n",
    "print(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_punctuation(post):\n",
    "    return ''.join([l for l in post if l not in string.punctuation])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_mbti['post'] = all_mbti['post'].apply(remove_punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'just when i think i’ve lost you just when i’m so tired i toss away the fight and say “i’ll just embrace my demons then… ‘cause you feel so far away and i’ll never be your angel” —that’s when'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_mbti['post'].iloc[268702]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like some punctation snuck through! See if you can figure out why?  **Hint** it has something to do with the standard encoding on text files in python..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Tokenising](http://www.nltk.org/howto/tokenize.html) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A tokenizer divides text into a sequence of tokens, which roughly correspond to \"words\". (see the [Stanford Tokeniser](https://nlp.stanford.edu/software/tokenizer.shtml))  We will use tokenisers to clean up the data, making it ready for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize, TreebankWordTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A',\n",
       " 'tokenizer',\n",
       " 'divides',\n",
       " 'text',\n",
       " 'into',\n",
       " 'a',\n",
       " 'sequence',\n",
       " 'of',\n",
       " 'tokens',\n",
       " ',',\n",
       " 'which',\n",
       " 'roughly',\n",
       " 'correspond',\n",
       " 'to',\n",
       " '``',\n",
       " 'words',\n",
       " \"''\",\n",
       " '.']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize('A tokenizer divides text into a sequence of tokens, which roughly correspond to \"words\".')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we will use the TreeBankWordTokenizer since it is MUCH quicker than the word_tokenise function\n",
    "tokeniser = TreebankWordTokenizer()\n",
    "all_mbti['tokens'] = all_mbti['post'].apply(tokeniser.tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['just',\n",
       " 'when',\n",
       " 'i',\n",
       " 'think',\n",
       " 'i',\n",
       " '’',\n",
       " 've',\n",
       " 'lost',\n",
       " 'you',\n",
       " 'just',\n",
       " 'when',\n",
       " 'i',\n",
       " '’',\n",
       " 'm',\n",
       " 'so',\n",
       " 'tired',\n",
       " 'i',\n",
       " 'toss',\n",
       " 'away',\n",
       " 'the',\n",
       " 'fight',\n",
       " 'and',\n",
       " 'say',\n",
       " '“',\n",
       " 'i',\n",
       " '’',\n",
       " 'll',\n",
       " 'just',\n",
       " 'embrace',\n",
       " 'my',\n",
       " 'demons',\n",
       " 'then…',\n",
       " '‘',\n",
       " 'cause',\n",
       " 'you',\n",
       " 'feel',\n",
       " 'so',\n",
       " 'far',\n",
       " 'away',\n",
       " 'and',\n",
       " 'i',\n",
       " '’',\n",
       " 'll',\n",
       " 'never',\n",
       " 'be',\n",
       " 'your',\n",
       " 'angel',\n",
       " '”',\n",
       " '—that',\n",
       " '’',\n",
       " 's',\n",
       " 'when']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_mbti['tokens'].iloc[268702]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Stemming](http://www.nltk.org/howto/stem.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stemming is the process of transforming to the root word, that is, it uses an algorithm that removes\n",
    "common word endings from English words, such as “ly,” “es,” “ed,” and “s.” \n",
    "\n",
    "For example, assuming for an analysis you may want to consider “carefully,” “cared,” “cares,” “caringly” as “care” instead of separate words. There are three widely used stemming algorithms, of which we will be using the `SnowballStemmer`:\n",
    "* Porter\n",
    "* Lancaster\n",
    "* Snowball"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk import SnowballStemmer, PorterStemmer, LancasterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words = 'caring cares cared caringly carefully'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "care\n",
      "care\n",
      "care\n",
      "care\n",
      "care\n"
     ]
    }
   ],
   "source": [
    "stemmer = SnowballStemmer('english')\n",
    "for word in words.split():\n",
    "    print(stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mbti_stemmer(words, stemmer):\n",
    "    return [stemmer.stem(word) for word in words]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_mbti['stem'] = all_mbti['tokens'].apply(mbti_stemmer, args=(stemmer, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "just                 --> just      \n",
      "when                 --> when      \n",
      "i                    --> i         \n",
      "think                --> think     \n",
      "i                    --> i         \n",
      "’                    --> ’         \n",
      "ve                   --> ve        \n",
      "lost                 --> lost      \n",
      "you                  --> you       \n",
      "just                 --> just      \n",
      "when                 --> when      \n",
      "i                    --> i         \n",
      "’                    --> ’         \n",
      "m                    --> m         \n",
      "so                   --> so        \n",
      "tired                --> tire      \n",
      "i                    --> i         \n",
      "toss                 --> toss      \n",
      "away                 --> away      \n",
      "the                  --> the       \n",
      "fight                --> fight     \n",
      "and                  --> and       \n",
      "say                  --> say       \n",
      "“                    --> “         \n",
      "i                    --> i         \n",
      "’                    --> ’         \n",
      "ll                   --> ll        \n",
      "just                 --> just      \n",
      "embrace              --> embrac    \n",
      "my                   --> my        \n",
      "demons               --> demon     \n",
      "then…                --> then…     \n",
      "‘                    --> ‘         \n",
      "cause                --> caus      \n",
      "you                  --> you       \n",
      "feel                 --> feel      \n",
      "so                   --> so        \n",
      "far                  --> far       \n",
      "away                 --> away      \n",
      "and                  --> and       \n",
      "i                    --> i         \n",
      "’                    --> ’         \n",
      "ll                   --> ll        \n",
      "never                --> never     \n",
      "be                   --> be        \n",
      "your                 --> your      \n",
      "angel                --> angel     \n",
      "”                    --> ”         \n",
      "—that                --> —that     \n",
      "’                    --> ’         \n",
      "s                    --> s         \n",
      "when                 --> when      \n"
     ]
    }
   ],
   "source": [
    "for i, t in enumerate(all_mbti.iloc[268702]['tokens']):    \n",
    "    print ('{:20s} --> {:10s}'.format(t, all_mbti.iloc[268702]['stem'][i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Lemmatization](https://pythonprogramming.net/lemmatizing-nltk-tutorial/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A very similar operation to stemming is called lemmatizing. Lemmatizing is the process of grouping words of similar meaning together. So, your root stem, meaning the word you end up with, is not something you can just look up in a dictionary, but you can look up a lemma.\n",
    "\n",
    "Some times you will wind up with a very similar word, but sometimes, you will wind up with a completely different word. Let's see some examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat\n",
      "cactus\n",
      "goose\n",
      "rock\n",
      "python\n",
      "good\n",
      "best\n",
      "run\n",
      "run\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "print(lemmatizer.lemmatize(\"cats\"))\n",
    "print(lemmatizer.lemmatize(\"cacti\"))\n",
    "print(lemmatizer.lemmatize(\"geese\"))\n",
    "print(lemmatizer.lemmatize(\"rocks\"))\n",
    "print(lemmatizer.lemmatize(\"python\"))\n",
    "print(lemmatizer.lemmatize(\"better\", pos=\"a\"))\n",
    "print(lemmatizer.lemmatize(\"best\", pos=\"a\"))\n",
    "print(lemmatizer.lemmatize(\"run\"))\n",
    "print(lemmatizer.lemmatize(\"run\",'v'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mbti_lemma(words, lemmatizer):\n",
    "    return [lemmatizer.lemmatize(word) for word in words]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_mbti['lemma'] = all_mbti['tokens'].apply(mbti_lemma, args=(lemmatizer, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "just                 --> just      \n",
      "when                 --> when      \n",
      "i                    --> i         \n",
      "think                --> think     \n",
      "i                    --> i         \n",
      "’                    --> ’         \n",
      "ve                   --> ve        \n",
      "lost                 --> lost      \n",
      "you                  --> you       \n",
      "just                 --> just      \n",
      "when                 --> when      \n",
      "i                    --> i         \n",
      "’                    --> ’         \n",
      "m                    --> m         \n",
      "so                   --> so        \n",
      "tired                --> tired     \n",
      "i                    --> i         \n",
      "toss                 --> toss      \n",
      "away                 --> away      \n",
      "the                  --> the       \n",
      "fight                --> fight     \n",
      "and                  --> and       \n",
      "say                  --> say       \n",
      "“                    --> “         \n",
      "i                    --> i         \n",
      "’                    --> ’         \n",
      "ll                   --> ll        \n",
      "just                 --> just      \n",
      "embrace              --> embrace   \n",
      "my                   --> my        \n",
      "demons               --> demon     \n",
      "then…                --> then…     \n",
      "‘                    --> ‘         \n",
      "cause                --> cause     \n",
      "you                  --> you       \n",
      "feel                 --> feel      \n",
      "so                   --> so        \n",
      "far                  --> far       \n",
      "away                 --> away      \n",
      "and                  --> and       \n",
      "i                    --> i         \n",
      "’                    --> ’         \n",
      "ll                   --> ll        \n",
      "never                --> never     \n",
      "be                   --> be        \n",
      "your                 --> your      \n",
      "angel                --> angel     \n",
      "”                    --> ”         \n",
      "—that                --> —that     \n",
      "’                    --> ’         \n",
      "s                    --> s         \n",
      "when                 --> when      \n"
     ]
    }
   ],
   "source": [
    "for i, t in enumerate(all_mbti.iloc[268702]['tokens']):    \n",
    "    print ('{:20s} --> {:10s}'.format(t, all_mbti.iloc[268702]['lemma'][i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [stopwords](http://johnlaudun.org/20130126-nltk-stopwords/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stop Words are words which do not contain important significance to be used in Search Queries. Usually these words are filtered out from search queries because they return a vast amount of unnecessary information.  See this [blog post](http://xpo6.com/list-of-english-stop-words/) for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " 'should',\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " 'couldn',\n",
       " 'didn',\n",
       " 'doesn',\n",
       " 'hadn',\n",
       " 'hasn',\n",
       " 'haven',\n",
       " 'isn',\n",
       " 'ma',\n",
       " 'mightn',\n",
       " 'mustn',\n",
       " 'needn',\n",
       " 'shan',\n",
       " 'shouldn',\n",
       " 'wasn',\n",
       " 'weren',\n",
       " 'won',\n",
       " 'wouldn']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may get a lookup error at this point!  Not to worry, this means you will need to download the corpora for the stops words.  Carry on below to get this! \n",
    "\n",
    "Remove the `# ` from the line below to bring up the NTLK downloader dialog box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# nltk.download()\n",
    "# or you can download the corpora directly\n",
    "# nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see this pop up box. Use it to find the stop word downloader... <img src=\"nlp/nltk_downloader.png\" />. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'about', 'above', 'after', 'again', 'against', 'ain', 'all', 'am', 'an']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(stopwords.words('english'))[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_stop_words(tokens):    \n",
    "    return [t for t in tokens if t not in stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's leave the stop words in for now so that we can test the following **Hypothesis**:\n",
    "* Introverts tend to use the word **`I`** more than extroverts\n",
    "* Conversely, Extroverts tend to favour the word **`you`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case you want to run the analysis again without stop words! Be warned, this can take long with the pandas apply function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# all_mbti['stem'] = all_mbti['tokens'].apply(remove_stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enough with the examples, why are we doing this already?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All that pre-processing allows us to finally do some analysis!  lets see what the 20 most common words in the whole text are. (Remember your first coding challenges?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Bag of words](https://www.packtpub.com/mapt/book/application_development/9781849513609/7/ch07lvl1sec73/bag-of-words-feature-extraction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text feature extraction is the process of transforming what is essentially a list of words into a feature set that is usable by a classifier. The NLTK classifiers expect dict style feature sets, so we must therefore transform our text into a dict. The Bag of Words model is the simplest method; it constructs a word presence feature set from all the words of an instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bag_of_words_count(words, word_dict={}):\n",
    "    \"\"\" this function takes in a list of words and returns a dictionary with each word as a key, \n",
    "        and the value represents the number of times that word appeared\"\"\"\n",
    "    for word in words:\n",
    "        if word in word_dict.keys():\n",
    "            word_dict[word] += 1\n",
    "        else:\n",
    "            word_dict[word] = 1\n",
    "    return word_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# here we create a set of dictionaries\n",
    "# one for each of the MBTI types\n",
    "personality = {}\n",
    "for pp in type_labels:\n",
    "    df = all_mbti.groupby('type')\n",
    "    personality[pp] = {}\n",
    "    for row in df.get_group(pp)['tokens']:\n",
    "        personality[pp] = bag_of_words_count(row, personality[pp])       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# next we create a list of all of the unique words...\n",
    "all_words = set()\n",
    "for pp in type_labels:\n",
    "    for word in personality[pp]:\n",
    "        all_words.add(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# so that we can create a dictionary of bag of words for the whole dataset\n",
    "personality['all'] = {}\n",
    "for pp in type_labels:    \n",
    "    for word in all_words:\n",
    "        if word in personality[pp].keys():\n",
    "            if word in personality['all']:\n",
    "                personality['all'][word] += personality[pp][word]\n",
    "            else:\n",
    "                personality['all'][word] = personality[pp][word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  1.58753000e+05,   2.30000000e+01,   5.00000000e+00,\n",
       "          2.00000000e+00,   2.00000000e+00,   0.00000000e+00,\n",
       "          2.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          1.00000000e+00]),\n",
       " array([  1.00000000e+00,   5.06139000e+04,   1.01226800e+05,\n",
       "          1.51839700e+05,   2.02452600e+05,   2.53065500e+05,\n",
       "          3.03678400e+05,   3.54291300e+05,   4.04904200e+05,\n",
       "          4.55517100e+05,   5.06130000e+05]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfUAAAFJCAYAAACCQLQfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xa3cd4ef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# lets have a look at the distrbution of words\n",
    "plt.hist([v for v in personality['all'].values()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of words that only appear once! Let's remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10980837"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many words in total?\n",
    "sum([v for v in personality['all'].values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98440"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many words appear only once?\n",
    "len([v for v in personality['all'].values() if v == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5194\n",
      "10249524\n"
     ]
    }
   ],
   "source": [
    "# how many words appear more than 100 times?\n",
    "# how many words of the total does that account for?\n",
    "print (len([v for v in personality['all'].values() if v >= 100]))\n",
    "print (sum([v for v in personality['all'].values() if v >= 100]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9428353785775723"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "11013261/11681001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using words that appear more than 100 times seems much more useful!  And this accounts for 94% of all the words!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_count = 100\n",
    "word_index = [k for k, v in personality['all'].items() if v > max_count]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# now let's create one big data frame with the word counts by personality profile\n",
    "hm = []\n",
    "for p, p_bow in personality.items():\n",
    "    df_bow = pd.DataFrame([(k, v) for k, v in p_bow.items() if k in word_index], columns=['Word', p])\n",
    "    df_bow.set_index('Word', inplace=True)\n",
    "    hm.append(df_bow)\n",
    "\n",
    "# create one big data frame\n",
    "df_bow = pd.concat(hm, axis=1)\n",
    "df_bow.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISTJ</th>\n",
       "      <th>ISFJ</th>\n",
       "      <th>INFJ</th>\n",
       "      <th>INTJ</th>\n",
       "      <th>ISTP</th>\n",
       "      <th>ISFP</th>\n",
       "      <th>INFP</th>\n",
       "      <th>INTP</th>\n",
       "      <th>ESTP</th>\n",
       "      <th>ESFP</th>\n",
       "      <th>ENFP</th>\n",
       "      <th>ENTP</th>\n",
       "      <th>ESTJ</th>\n",
       "      <th>ESFJ</th>\n",
       "      <th>ENFJ</th>\n",
       "      <th>ENTJ</th>\n",
       "      <th>all</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>i</th>\n",
       "      <td>11631.0</td>\n",
       "      <td>10476.0</td>\n",
       "      <td>91321</td>\n",
       "      <td>57892.0</td>\n",
       "      <td>17963.0</td>\n",
       "      <td>15449.0</td>\n",
       "      <td>115993</td>\n",
       "      <td>71312</td>\n",
       "      <td>4688.0</td>\n",
       "      <td>2289.0</td>\n",
       "      <td>42159.0</td>\n",
       "      <td>35863</td>\n",
       "      <td>2313.0</td>\n",
       "      <td>2742.0</td>\n",
       "      <td>11927.0</td>\n",
       "      <td>12112.0</td>\n",
       "      <td>506130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>7401.0</td>\n",
       "      <td>5547.0</td>\n",
       "      <td>53659</td>\n",
       "      <td>40218.0</td>\n",
       "      <td>11626.0</td>\n",
       "      <td>8376.0</td>\n",
       "      <td>63949</td>\n",
       "      <td>48488</td>\n",
       "      <td>2772.0</td>\n",
       "      <td>1312.0</td>\n",
       "      <td>22834.0</td>\n",
       "      <td>24608</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>1440.0</td>\n",
       "      <td>6581.0</td>\n",
       "      <td>8445.0</td>\n",
       "      <td>308539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>7278.0</td>\n",
       "      <td>6154.0</td>\n",
       "      <td>54588</td>\n",
       "      <td>38081.0</td>\n",
       "      <td>11380.0</td>\n",
       "      <td>8630.0</td>\n",
       "      <td>65178</td>\n",
       "      <td>44947</td>\n",
       "      <td>2760.0</td>\n",
       "      <td>1313.0</td>\n",
       "      <td>23193.0</td>\n",
       "      <td>23004</td>\n",
       "      <td>1362.0</td>\n",
       "      <td>1528.0</td>\n",
       "      <td>7227.0</td>\n",
       "      <td>8091.0</td>\n",
       "      <td>304714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>5684.0</td>\n",
       "      <td>4532.0</td>\n",
       "      <td>43314</td>\n",
       "      <td>30079.0</td>\n",
       "      <td>9475.0</td>\n",
       "      <td>6690.0</td>\n",
       "      <td>53623</td>\n",
       "      <td>36445</td>\n",
       "      <td>2334.0</td>\n",
       "      <td>1078.0</td>\n",
       "      <td>19131.0</td>\n",
       "      <td>19314</td>\n",
       "      <td>1062.0</td>\n",
       "      <td>1223.0</td>\n",
       "      <td>5272.0</td>\n",
       "      <td>6568.0</td>\n",
       "      <td>245824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>5440.0</td>\n",
       "      <td>4758.0</td>\n",
       "      <td>43097</td>\n",
       "      <td>28224.0</td>\n",
       "      <td>8596.0</td>\n",
       "      <td>7116.0</td>\n",
       "      <td>54043</td>\n",
       "      <td>33739</td>\n",
       "      <td>2371.0</td>\n",
       "      <td>1131.0</td>\n",
       "      <td>20573.0</td>\n",
       "      <td>18417</td>\n",
       "      <td>1169.0</td>\n",
       "      <td>1217.0</td>\n",
       "      <td>5908.0</td>\n",
       "      <td>6302.0</td>\n",
       "      <td>242101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>of</th>\n",
       "      <td>4311.0</td>\n",
       "      <td>3367.0</td>\n",
       "      <td>32774</td>\n",
       "      <td>23413.0</td>\n",
       "      <td>6523.0</td>\n",
       "      <td>4917.0</td>\n",
       "      <td>39499</td>\n",
       "      <td>29049</td>\n",
       "      <td>1605.0</td>\n",
       "      <td>768.0</td>\n",
       "      <td>14041.0</td>\n",
       "      <td>14617</td>\n",
       "      <td>806.0</td>\n",
       "      <td>941.0</td>\n",
       "      <td>4087.0</td>\n",
       "      <td>4848.0</td>\n",
       "      <td>185566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>you</th>\n",
       "      <td>3853.0</td>\n",
       "      <td>2992.0</td>\n",
       "      <td>29855</td>\n",
       "      <td>20960.0</td>\n",
       "      <td>6089.0</td>\n",
       "      <td>4495.0</td>\n",
       "      <td>32969</td>\n",
       "      <td>23153</td>\n",
       "      <td>1749.0</td>\n",
       "      <td>814.0</td>\n",
       "      <td>13998.0</td>\n",
       "      <td>13971</td>\n",
       "      <td>813.0</td>\n",
       "      <td>765.0</td>\n",
       "      <td>4097.0</td>\n",
       "      <td>5202.0</td>\n",
       "      <td>165775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>that</th>\n",
       "      <td>3254.0</td>\n",
       "      <td>2762.0</td>\n",
       "      <td>26329</td>\n",
       "      <td>19013.0</td>\n",
       "      <td>5352.0</td>\n",
       "      <td>4032.0</td>\n",
       "      <td>31134</td>\n",
       "      <td>22478</td>\n",
       "      <td>1310.0</td>\n",
       "      <td>697.0</td>\n",
       "      <td>11896.0</td>\n",
       "      <td>11545</td>\n",
       "      <td>661.0</td>\n",
       "      <td>754.0</td>\n",
       "      <td>3533.0</td>\n",
       "      <td>3899.0</td>\n",
       "      <td>148649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is</th>\n",
       "      <td>3119.0</td>\n",
       "      <td>2520.0</td>\n",
       "      <td>24646</td>\n",
       "      <td>18676.0</td>\n",
       "      <td>4850.0</td>\n",
       "      <td>3794.0</td>\n",
       "      <td>27995</td>\n",
       "      <td>21745</td>\n",
       "      <td>1371.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>10837.0</td>\n",
       "      <td>11431</td>\n",
       "      <td>682.0</td>\n",
       "      <td>686.0</td>\n",
       "      <td>3212.0</td>\n",
       "      <td>4065.0</td>\n",
       "      <td>140269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>it</th>\n",
       "      <td>3202.0</td>\n",
       "      <td>2728.0</td>\n",
       "      <td>24840</td>\n",
       "      <td>17410.0</td>\n",
       "      <td>5538.0</td>\n",
       "      <td>4062.0</td>\n",
       "      <td>29918</td>\n",
       "      <td>21348</td>\n",
       "      <td>1309.0</td>\n",
       "      <td>584.0</td>\n",
       "      <td>10855.0</td>\n",
       "      <td>10546</td>\n",
       "      <td>609.0</td>\n",
       "      <td>610.0</td>\n",
       "      <td>3062.0</td>\n",
       "      <td>3592.0</td>\n",
       "      <td>140213</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ISTJ     ISFJ   INFJ     INTJ     ISTP     ISFP    INFP   INTP  \\\n",
       "i     11631.0  10476.0  91321  57892.0  17963.0  15449.0  115993  71312   \n",
       "the    7401.0   5547.0  53659  40218.0  11626.0   8376.0   63949  48488   \n",
       "to     7278.0   6154.0  54588  38081.0  11380.0   8630.0   65178  44947   \n",
       "a      5684.0   4532.0  43314  30079.0   9475.0   6690.0   53623  36445   \n",
       "and    5440.0   4758.0  43097  28224.0   8596.0   7116.0   54043  33739   \n",
       "of     4311.0   3367.0  32774  23413.0   6523.0   4917.0   39499  29049   \n",
       "you    3853.0   2992.0  29855  20960.0   6089.0   4495.0   32969  23153   \n",
       "that   3254.0   2762.0  26329  19013.0   5352.0   4032.0   31134  22478   \n",
       "is     3119.0   2520.0  24646  18676.0   4850.0   3794.0   27995  21745   \n",
       "it     3202.0   2728.0  24840  17410.0   5538.0   4062.0   29918  21348   \n",
       "\n",
       "        ESTP    ESFP     ENFP   ENTP    ESTJ    ESFJ     ENFJ     ENTJ     all  \n",
       "i     4688.0  2289.0  42159.0  35863  2313.0  2742.0  11927.0  12112.0  506130  \n",
       "the   2772.0  1312.0  22834.0  24608  1283.0  1440.0   6581.0   8445.0  308539  \n",
       "to    2760.0  1313.0  23193.0  23004  1362.0  1528.0   7227.0   8091.0  304714  \n",
       "a     2334.0  1078.0  19131.0  19314  1062.0  1223.0   5272.0   6568.0  245824  \n",
       "and   2371.0  1131.0  20573.0  18417  1169.0  1217.0   5908.0   6302.0  242101  \n",
       "of    1605.0   768.0  14041.0  14617   806.0   941.0   4087.0   4848.0  185566  \n",
       "you   1749.0   814.0  13998.0  13971   813.0   765.0   4097.0   5202.0  165775  \n",
       "that  1310.0   697.0  11896.0  11545   661.0   754.0   3533.0   3899.0  148649  \n",
       "is    1371.0   640.0  10837.0  11431   682.0   686.0   3212.0   4065.0  140269  \n",
       "it    1309.0   584.0  10855.0  10546   609.0   610.0   3062.0   3592.0  140213  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what are the top 10 words that appear most often?\n",
    "df_bow.sort_values(by='all', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thats not very helpful at all, is it! Its very difficult to extract insight from this data.  Lets see if we can use the $chi^2$ test to see whether Introverts favour the word **`I`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "intro_types = [p for p in type_labels if p[0] == 'I']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ISTJ', 'ISFJ', 'INFJ', 'INTJ', 'ISTP', 'ISFP', 'INFP', 'INTP']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intro_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_bow['I'] = df_bow[intro_types].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert to percentages\n",
    "for col in ['I', 'all']:\n",
    "    df_bow[col+'_perc'] = df_bow[col] / df_bow[col].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do you remember the chi2 test from the CINDY framework?  This looks at observed versus expected results and lets us know where the greatest differences from expected are.  The bigger the statistic, the greater the difference from expectation.  The formula is \n",
    "\n",
    "$$𝑐ℎ𝑖^2 = \\sum{\\frac{(𝑂𝑏𝑠𝑒𝑟𝑣𝑒𝑑 −𝑒𝑥𝑝𝑒𝑐𝑡𝑒𝑑)^2}{𝑒𝑥𝑝𝑒𝑐𝑡𝑒𝑑}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_bow['chi2'] = np.power((df_bow['I_perc'] - df_bow['all_perc']), 2) / df_bow['all_perc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>I_perc</th>\n",
       "      <th>all_perc</th>\n",
       "      <th>chi2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>urlweb</th>\n",
       "      <td>0.002950</td>\n",
       "      <td>0.002748</td>\n",
       "      <td>0.000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>infp</th>\n",
       "      <td>0.001299</td>\n",
       "      <td>0.001168</td>\n",
       "      <td>0.000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>infps</th>\n",
       "      <td>0.000478</td>\n",
       "      <td>0.000426</td>\n",
       "      <td>0.000006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>infj</th>\n",
       "      <td>0.001146</td>\n",
       "      <td>0.001063</td>\n",
       "      <td>0.000006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>intp</th>\n",
       "      <td>0.000984</td>\n",
       "      <td>0.000909</td>\n",
       "      <td>0.000006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>infjs</th>\n",
       "      <td>0.000407</td>\n",
       "      <td>0.000368</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>intps</th>\n",
       "      <td>0.000351</td>\n",
       "      <td>0.000319</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in</th>\n",
       "      <td>0.012965</td>\n",
       "      <td>0.012771</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i</th>\n",
       "      <td>0.049770</td>\n",
       "      <td>0.049400</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>my</th>\n",
       "      <td>0.012520</td>\n",
       "      <td>0.012341</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          I_perc  all_perc      chi2\n",
       "urlweb  0.002950  0.002748  0.000015\n",
       "infp    0.001299  0.001168  0.000015\n",
       "infps   0.000478  0.000426  0.000006\n",
       "infj    0.001146  0.001063  0.000006\n",
       "intp    0.000984  0.000909  0.000006\n",
       "infjs   0.000407  0.000368  0.000004\n",
       "intps   0.000351  0.000319  0.000003\n",
       "in      0.012965  0.012771  0.000003\n",
       "i       0.049770  0.049400  0.000003\n",
       "my      0.012520  0.012341  0.000003"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bow[['I_perc', 'all_perc', 'chi2']][df_bow['I_perc'] > df_bow['all_perc']].sort_values(by='chi2', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And there it is! What can we conclude from this:\n",
    "* I is the 9th most introverted word, by expectation\n",
    "* Introverts tend to post more urls than extroverted people too! \n",
    "* The introverted types are more likely to be written by Introverts, maybe because people post about their own types?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>I_perc</th>\n",
       "      <th>all_perc</th>\n",
       "      <th>chi2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>enfp</th>\n",
       "      <td>0.000473</td>\n",
       "      <td>0.000763</td>\n",
       "      <td>0.000110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entp</th>\n",
       "      <td>0.000394</td>\n",
       "      <td>0.000651</td>\n",
       "      <td>0.000101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entps</th>\n",
       "      <td>0.000121</td>\n",
       "      <td>0.000229</td>\n",
       "      <td>0.000051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>enfps</th>\n",
       "      <td>0.000138</td>\n",
       "      <td>0.000244</td>\n",
       "      <td>0.000046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entj</th>\n",
       "      <td>0.000265</td>\n",
       "      <td>0.000377</td>\n",
       "      <td>0.000034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>enfj</th>\n",
       "      <td>0.000288</td>\n",
       "      <td>0.000375</td>\n",
       "      <td>0.000020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>estp</th>\n",
       "      <td>0.000225</td>\n",
       "      <td>0.000290</td>\n",
       "      <td>0.000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entjs</th>\n",
       "      <td>0.000070</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>0.000014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d</th>\n",
       "      <td>0.000397</td>\n",
       "      <td>0.000469</td>\n",
       "      <td>0.000011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>enfjs</th>\n",
       "      <td>0.000077</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ne</th>\n",
       "      <td>0.000268</td>\n",
       "      <td>0.000325</td>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7w6</th>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>you</th>\n",
       "      <td>0.015788</td>\n",
       "      <td>0.016180</td>\n",
       "      <td>0.000009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7w8</th>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>he</th>\n",
       "      <td>0.002483</td>\n",
       "      <td>0.002631</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lol</th>\n",
       "      <td>0.000744</td>\n",
       "      <td>0.000825</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>an</th>\n",
       "      <td>0.005831</td>\n",
       "      <td>0.006041</td>\n",
       "      <td>0.000007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>guys</th>\n",
       "      <td>0.000549</td>\n",
       "      <td>0.000610</td>\n",
       "      <td>0.000006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xd</th>\n",
       "      <td>0.000226</td>\n",
       "      <td>0.000266</td>\n",
       "      <td>0.000006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>estps</th>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>0.000005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         I_perc  all_perc      chi2\n",
       "enfp   0.000473  0.000763  0.000110\n",
       "entp   0.000394  0.000651  0.000101\n",
       "entps  0.000121  0.000229  0.000051\n",
       "enfps  0.000138  0.000244  0.000046\n",
       "entj   0.000265  0.000377  0.000034\n",
       "enfj   0.000288  0.000375  0.000020\n",
       "estp   0.000225  0.000290  0.000015\n",
       "entjs  0.000070  0.000108  0.000014\n",
       "d      0.000397  0.000469  0.000011\n",
       "enfjs  0.000077  0.000110  0.000010\n",
       "ne     0.000268  0.000325  0.000010\n",
       "7w6    0.000020  0.000039  0.000010\n",
       "you    0.015788  0.016180  0.000009\n",
       "7w8    0.000012  0.000028  0.000009\n",
       "he     0.002483  0.002631  0.000008\n",
       "lol    0.000744  0.000825  0.000008\n",
       "an     0.005831  0.006041  0.000007\n",
       "guys   0.000549  0.000610  0.000006\n",
       "xd     0.000226  0.000266  0.000006\n",
       "estps  0.000044  0.000063  0.000005"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bow[['I_perc', 'all_perc', 'chi2']][df_bow['I_perc'] < df_bow['all_perc']].sort_values(by='chi2', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now that we have done all of that, lets cheat!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Praise be to Python...\n",
    "\n",
    "sklearn has a built in text feature extraction module called [CountVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) that will literally do all that work in one line of code!\n",
    "\n",
    "\n",
    "This function converts a collection of text documents to a matrix of token counts.\n",
    "\n",
    "This implementation produces a sparse representation of the counts using scipy.sparse.csr_matrix.\n",
    "\n",
    "If you do not provide an a-priori dictionary and you do not use an analyzer that does some kind of feature selection then the number of features will be equal to the vocabulary size found by analyzing the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vect = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vect.fit(all_mbti['post'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning the vectorizer (discussion)\n",
    "\n",
    "Thus far, we have been using the default parameters of [CountVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### show default parameters for CountVectorizer\n",
    "vect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, the vectorizer is worth tuning, just like a model is worth tuning! Here are a few parameters that you might want to tune:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **stop_words:** string {'english'}, list, or None (default)\n",
    "    - If 'english', a built-in stop word list for English is used.\n",
    "    - If a list, that list is assumed to contain stop words, all of which will be removed from the resulting tokens.\n",
    "    - If None, no stop words will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remove English stop words\n",
    "vect = CountVectorizer(stop_words='english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **ngram_range:** tuple (min_n, max_n), default=(1, 1)\n",
    "    - The lower and upper boundary of the range of n-values for different n-grams to be extracted.\n",
    "    - All values of n such that min_n <= n <= max_n will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# include 1-grams and 2-grams\n",
    "vect = CountVectorizer(ngram_range=(1, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **max_df:** float in range [0.0, 1.0] or int, default=1.0\n",
    "    - When building the vocabulary, ignore terms that have a document frequency strictly higher than the given threshold (corpus-specific stop words).\n",
    "    - If float, the parameter represents a proportion of documents.\n",
    "    - If integer, the parameter represents an absolute count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ignore terms that appear in more than 50% of the documents\n",
    "vect = CountVectorizer(max_df=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **min_df:** float in range [0.0, 1.0] or int, default=1\n",
    "    - When building the vocabulary, ignore terms that have a document frequency strictly lower than the given threshold. (This value is also called \"cut-off\" in the literature.)\n",
    "    - If float, the parameter represents a proportion of documents.\n",
    "    - If integer, the parameter represents an absolute count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# only keep terms that appear in at least 2 documents\n",
    "vect = CountVectorizer(min_df=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Guidelines for tuning CountVectorizer:**\n",
    "\n",
    "- Use your knowledge of the **problem** and the **text**, and your understanding of the **tuning parameters**, to help you decide what parameters to tune and how to tune them.\n",
    "- **Experiment**, and let the data tell you the best approach!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "betterVect = CountVectorizer(stop_words='english', min_df=2, max_df=0.5, ngram_range=(1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "betterVect.fit(all_mbti['post'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(betterVect.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [ngrams](http://www.nltk.org/api/nltk.html?highlight=n%20grams#nltk.util.ngrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While individual words do carry meaning, it is often the case that combinations of words change meanings of sentences entirely.  For example, what difference does removing the `not` from this sentence make?\n",
    "\n",
    "Natural Language processing is **not** easy!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ngrams are a method to extract combinations of words into features for model buildiing.  The `n` in ngrams specifies the number of tokens to include.  For example, a 2-gram returns all the consecutive pairs of words in a sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.util import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def word_grams(words, min_n=1, max_n=4):\n",
    "    s = []\n",
    "    for n in range(min_n, max_n):\n",
    "        for ngram in ngrams(words, n):\n",
    "            s.append(' '.join(str(i) for i in ngram))\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['one', 'two', 'three', 'four', 'one two', 'two three', 'three four', 'one two three', 'two three four']\n"
     ]
    }
   ],
   "source": [
    "print (word_grams('one two three four'.split(' ')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('just', 'when'),\n",
       " ('when', 'i'),\n",
       " ('i', 'think'),\n",
       " ('think', 'i'),\n",
       " ('i', '’'),\n",
       " ('’', 've'),\n",
       " ('ve', 'lost'),\n",
       " ('lost', 'you'),\n",
       " ('you', 'just'),\n",
       " ('just', 'when'),\n",
       " ('when', 'i'),\n",
       " ('i', '’'),\n",
       " ('’', 'm'),\n",
       " ('m', 'so'),\n",
       " ('so', 'tired'),\n",
       " ('tired', 'i'),\n",
       " ('i', 'toss'),\n",
       " ('toss', 'away'),\n",
       " ('away', 'the'),\n",
       " ('the', 'fight'),\n",
       " ('fight', 'and'),\n",
       " ('and', 'say'),\n",
       " ('say', '“'),\n",
       " ('“', 'i'),\n",
       " ('i', '’'),\n",
       " ('’', 'll'),\n",
       " ('ll', 'just'),\n",
       " ('just', 'embrace'),\n",
       " ('embrace', 'my'),\n",
       " ('my', 'demons'),\n",
       " ('demons', 'then…'),\n",
       " ('then…', '‘'),\n",
       " ('‘', 'cause'),\n",
       " ('cause', 'you'),\n",
       " ('you', 'feel'),\n",
       " ('feel', 'so'),\n",
       " ('so', 'far'),\n",
       " ('far', 'away'),\n",
       " ('away', 'and'),\n",
       " ('and', 'i'),\n",
       " ('i', '’'),\n",
       " ('’', 'll'),\n",
       " ('ll', 'never'),\n",
       " ('never', 'be'),\n",
       " ('be', 'your'),\n",
       " ('your', 'angel'),\n",
       " ('angel', '”'),\n",
       " ('”', '—that'),\n",
       " ('—that', '’'),\n",
       " ('’', 's'),\n",
       " ('s', 'when')]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x in ngrams(all_mbti.iloc[268702]['tokens'], 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('just', 'when', 'i'),\n",
       " ('when', 'i', 'think'),\n",
       " ('i', 'think', 'i'),\n",
       " ('think', 'i', '’'),\n",
       " ('i', '’', 've'),\n",
       " ('’', 've', 'lost'),\n",
       " ('ve', 'lost', 'you'),\n",
       " ('lost', 'you', 'just'),\n",
       " ('you', 'just', 'when'),\n",
       " ('just', 'when', 'i'),\n",
       " ('when', 'i', '’'),\n",
       " ('i', '’', 'm'),\n",
       " ('’', 'm', 'so'),\n",
       " ('m', 'so', 'tired'),\n",
       " ('so', 'tired', 'i'),\n",
       " ('tired', 'i', 'toss'),\n",
       " ('i', 'toss', 'away'),\n",
       " ('toss', 'away', 'the'),\n",
       " ('away', 'the', 'fight'),\n",
       " ('the', 'fight', 'and'),\n",
       " ('fight', 'and', 'say'),\n",
       " ('and', 'say', '“'),\n",
       " ('say', '“', 'i'),\n",
       " ('“', 'i', '’'),\n",
       " ('i', '’', 'll'),\n",
       " ('’', 'll', 'just'),\n",
       " ('ll', 'just', 'embrace'),\n",
       " ('just', 'embrace', 'my'),\n",
       " ('embrace', 'my', 'demons'),\n",
       " ('my', 'demons', 'then…'),\n",
       " ('demons', 'then…', '‘'),\n",
       " ('then…', '‘', 'cause'),\n",
       " ('‘', 'cause', 'you'),\n",
       " ('cause', 'you', 'feel'),\n",
       " ('you', 'feel', 'so'),\n",
       " ('feel', 'so', 'far'),\n",
       " ('so', 'far', 'away'),\n",
       " ('far', 'away', 'and'),\n",
       " ('away', 'and', 'i'),\n",
       " ('and', 'i', '’'),\n",
       " ('i', '’', 'll'),\n",
       " ('’', 'll', 'never'),\n",
       " ('ll', 'never', 'be'),\n",
       " ('never', 'be', 'your'),\n",
       " ('be', 'your', 'angel'),\n",
       " ('your', 'angel', '”'),\n",
       " ('angel', '”', '—that'),\n",
       " ('”', '—that', '’'),\n",
       " ('—that', '’', 's'),\n",
       " ('’', 's', 'when')]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x in ngrams(all_mbti.iloc[268702]['tokens'], 3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
